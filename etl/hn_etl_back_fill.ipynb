{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from decouple import config \n",
    "import psycopg2\n",
    "\n",
    "\n",
    "def hn_scrape(i,comments_list):\n",
    "    r = requests.get('https://hacker-news.firebaseio.com/v0/item/'+str(i)+'.json').json()\n",
    "    try:\n",
    "        if ('deleted' in r.keys()):\n",
    "            pass\n",
    "        else:\n",
    "            if r[\"type\"] == 'comment':\n",
    "                t = (r[\"by\"],r[\"id\"],r[\"text\"],r[\"time\"])\n",
    "                comments_list.append(t)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def sentiment(text):\n",
    "    payload = {'text':text}\n",
    "    try:\n",
    "        return requests.get('https://crawftv-nlp-api.herokuapp.com/sentiment',params=payload).json()[\"compound\"]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "@task\n",
    "def extract():\n",
    "    comments_list = []\n",
    "    conn = db.connect()\n",
    "    curs = conn.connection.cursor()\n",
    "    curs.execute(\" SELECT MIN(id) FROM comments\")\n",
    "    table_min = curs.fetchall()\n",
    "    table_min = int(table_min[0][0])\n",
    "    conn.close()\n",
    "    curs.close()\n",
    "    for i in range(table_min-10000,table_min,1):\n",
    "        hn_scrape(i,comments_list)\n",
    "    return comments_list\n",
    "    \n",
    "    \n",
    "\n",
    "@task\n",
    "def transform(comments_list):\n",
    "    comments= pd.DataFrame(columns = [\"by\", \"id\",\"text\",\"time\"], data=comments_list)\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"&quot;\",\"\")\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"&#x27;\",\"'\")\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"&gt; \",\" \")\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"<p>\",\" \")\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"<a>\",\" \")\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"</a>\",\" \")\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"<i>\",\" \")\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"</i>\",\" \")\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"&#x2F;\",'')\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"https:\",' ')\n",
    "    comments[\"text\"] = comments[\"text\"].str.replace(\"\\\\n\",' ')\n",
    "    comments = comments.dropna()\n",
    "    return comments\n",
    "\n",
    "\n",
    "@task\n",
    "def load(comments):\n",
    "    comments[\"sentiment\"] = comments[\"text\"].apply(sentiment)\n",
    "    conn = db.connect()\n",
    "    curs = conn.connection.cursor()\n",
    "    comments.to_sql(name=\"comments\",con=db, if_exists=\"append\",chunksize=500)\n",
    "    conn.close()\n",
    "    curs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-09-11 20:25:55,731] INFO - prefect.FlowRunner | Beginning Flow run for 'ETL'\n",
      "[2019-09-11 20:25:55,731] INFO - prefect.FlowRunner | Starting flow run.\n",
      "[2019-09-11 20:25:55,735] INFO - prefect.TaskRunner | Task 'extract': Starting task run...\n",
      "[2019-09-11 20:44:48,572] INFO - prefect.TaskRunner | Task 'extract': finished task run for task with final state: 'Success'\n",
      "[2019-09-11 20:44:48,575] INFO - prefect.TaskRunner | Task 'transform': Starting task run...\n",
      "[2019-09-11 20:44:48,681] INFO - prefect.TaskRunner | Task 'transform': finished task run for task with final state: 'Success'\n",
      "[2019-09-11 20:44:48,682] INFO - prefect.TaskRunner | Task 'load': Starting task run...\n"
     ]
    }
   ],
   "source": [
    "from prefect import Flow\n",
    "host = config('AWS_DATABASE_URL')\n",
    "db = sqlalchemy.create_engine(host)\n",
    "\n",
    "\n",
    "with Flow('ETL') as flow:\n",
    "    e = extract()\n",
    "    t = transform(e)\n",
    "    l = load(t)\n",
    "\n",
    "flow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
